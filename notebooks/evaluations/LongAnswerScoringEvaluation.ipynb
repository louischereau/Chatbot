{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9WJaEyOaFXj",
        "outputId": "304c6b29-fb38-42b4-fcfc-72efae358354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 200 kB 12.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 67.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 62.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 62.2 MB/s \n",
            "\u001b[?25h  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting adjustText\n",
            "  Downloading adjustText-0.7.3.tar.gz (7.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from adjustText) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from adjustText) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->adjustText) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->adjustText) (1.15.0)\n",
            "Building wheels for collected packages: adjustText\n",
            "  Building wheel for adjustText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adjustText: filename=adjustText-0.7.3-py3-none-any.whl size=7097 sha256=89ab6815727e77dde562378b4ceddac35d623e16673acf4082546c66fb6c6fe8\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/98/32/afbf902d8f040fadfdf0a44357e4ab750afe165d873bf5893d\n",
            "Successfully built adjustText\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-0.7.3\n"
          ]
        }
      ],
      "source": [
        "#!pip install --quiet textacy\n",
        "!pip install --quiet wikipedia-api\n",
        "!pip install adjustText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4WY-VVK6RJk"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/dqxiu/ParaSCI.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTF7ChMiVFX9"
      },
      "outputs": [],
      "source": [
        "!unzip squad_folds_eval.zip\n",
        "!unzip hotpotqa_folds_eval.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7kBffR7rCfa"
      },
      "outputs": [],
      "source": [
        "result = !wget --save-cookies cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p'\n",
        "code = result[-1]\n",
        "arg =' --load-cookies cookies.txt \"https://docs.google.com/uc?export=download&confirm=%s&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\" -O GoogleNews-vectors-negative300.bin.gz' % code\n",
        "!wget $arg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cXSnygyaefR",
        "outputId": "34a5af30-3a3a-4824-8b47-7751b3174469"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wikipediaapi\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import textacy\n",
        "from gensim import models\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
        "#from textacy.similarity.edits import levenshtein\n",
        "import os\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tioS3KCQYwqq"
      },
      "outputs": [],
      "source": [
        "def get_paraphrase_dataset():\n",
        "\n",
        "  data = {\"text\":[], \"paraphrased_text\":[]}\n",
        "\n",
        "  paths = [\"ParaSCI/Data/ParaSCI-ACL\", \"ParaSCI/Data/ParaSCI-arXiv\"]\n",
        "\n",
        "\n",
        "  for path in paths:\n",
        "    for directory in os.listdir(path):\n",
        "      if directory in [\"train\", \"val\", \"test\"]:\n",
        "        source = open(path + \"/\" + directory + \"/\" + directory + \".src\").read().split(\"\\n\")\n",
        "        target = open(path + \"/\" + directory + \"/\" + directory + \".tgt\").read().split(\"\\n\")\n",
        "        for line in source:\n",
        "          data[\"text\"].append(line)\n",
        "        for line in target:\n",
        "          data[\"paraphrased_text\"].append(line)\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  #df.dropna(inplace=True)\n",
        "  df[\"is_paraphrase\"] = [1] * len(df)\n",
        "  \n",
        "  df_false = df.copy()\n",
        "  data_to_shuffle = df_false[\"paraphrased_text\"]\n",
        "  \n",
        "  shuffled_data = data_to_shuffle.sample(frac=1).reset_index(drop=True)\n",
        " \n",
        "  df_false[\"paraphrased_text\"] = list(shuffled_data)\n",
        "  \n",
        "  df_false[\"is_paraphrase\"] = [0] * len(df_false)\n",
        " \n",
        "  df = df.sample(500)\n",
        "  df_false = df_false.sample(500)\n",
        "  df = df.append(df_false)\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVcsUZ0Ofx0Y"
      },
      "outputs": [],
      "source": [
        "def _convert_tag(tag):\n",
        "    \"\"\"Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets\"\"\"\n",
        "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
        "    try:\n",
        "        return tag_dict[tag[0]]\n",
        "    except KeyError:\n",
        "        return None\n",
        "\n",
        "def _doc_to_synsets(doc : string):\n",
        "    \"\"\"\n",
        "    Returns a list of synsets in document.\n",
        "    Tokenizes and tags the words in the document doc.\n",
        "    Then finds the first synset for each word/tag combination.\n",
        "    If a synset is not found for that combination it is skipped.\n",
        "    Args:\n",
        "    doc: string to be converted\n",
        "    Returns:\n",
        "    list of synsets\n",
        "    Example:\n",
        "    doc_to_synsets('Fish are nvqjp friends.')\n",
        "    Out: [Synset('fish.n.01'), Synset('be.v.01'), Synset('friend.n.01')]\n",
        "    \"\"\"\n",
        "\n",
        "    doc_tokenized = nltk.word_tokenize(doc)\n",
        "    doc_tokenized_tagged = nltk.pos_tag(doc_tokenized)\n",
        "    tags = [x[1] for x in doc_tokenized_tagged]\n",
        "    new_tags =[_convert_tag(tag) for tag in tags]\n",
        "    new_doc_tokenized_tagged = list(zip(doc_tokenized, new_tags))\n",
        "    synsets = [wn.synsets(x[0], x[1])[0] for x in new_doc_tokenized_tagged if len(wn.synsets(x[0], x[1])) > 0]\n",
        "    return synsets\n",
        "\n",
        "def _similarity_score(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculate the normalized similarity score of s1 onto s2\n",
        "    For each synset in s1, finds the synset in s2 with the largest similarity value.\n",
        "    Sum of all of the largest similarity values and normalize this value by dividing it by the\n",
        "    number of largest similarity values found.\n",
        "    Args:\n",
        "    s1, s2: list of synsets from doc_to_synsets\n",
        "    Returns:\n",
        "    normalized similarity score of s1 onto s2\n",
        "    Example:\n",
        "    synsets1 = doc_to_synsets('I like cats')\n",
        "    synsets2 = doc_to_synsets('I like dogs')\n",
        "    similarity_score(synsets1, synsets2)\n",
        "    Out: 0.73333333333333339\n",
        "    \"\"\"\n",
        "    scores = list()\n",
        "    for x in s1:\n",
        "        scores.append([x.path_similarity(y) for y in s2 if x.path_similarity(y) != None])\n",
        "    no_empty_list_scores = [x for x in scores if x !=[]]\n",
        "    best_scores = [max(x) for x in no_empty_list_scores]\n",
        "    if len(best_scores) == 0:\n",
        "        return 0\n",
        "    normalized_score = sum(best_scores)/len(best_scores)\n",
        "    return normalized_score\n",
        "\n",
        "def document_path_similarity(doc1 : string, doc2 : string):\n",
        "    \"\"\"Finds the symmetrical similarity between doc1 and doc2\"\"\"\n",
        "    synsets1 = _doc_to_synsets(doc1)\n",
        "    synsets2 = _doc_to_synsets(doc2)\n",
        "    return (_similarity_score(synsets1, synsets2) + _similarity_score(synsets2, synsets1)) / 2\n",
        "\n",
        "\n",
        "\n",
        "def document_vector(doc : string):\n",
        "  \n",
        "    doc = word_tokenize(doc)\n",
        "\n",
        "    words = []\n",
        "\n",
        "    for word in doc:\n",
        "      if word.isnumeric():\n",
        "        for digit in word:\n",
        "          words.append(digit)\n",
        "      if list(model.vocab).count(word) == 1:\n",
        "        words.append(word)\n",
        "    \n",
        "    if len(words) > 0:\n",
        "      return np.mean(model[words], axis=0)\n",
        "\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saSbb7hdjjha"
      },
      "outputs": [],
      "source": [
        "def predict_is_paraphrase_dps(row, threshold):\n",
        "\n",
        "  text1 = str(row[\"text\"])\n",
        "  text2 = str(row[\"paraphrased_text\"])\n",
        "  if document_path_similarity(text1,  text2) > threshold:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "def predict_is_paraphrase_word2vec(row, threshold):\n",
        "  text1 = row[\"text\"]\n",
        "  text2 = row[\"paraphrased_text\"]\n",
        "  doc_vec1 = document_vector(str(text1))\n",
        "  doc_vec2 = document_vector(str(text2))\n",
        "\n",
        "  if len(doc_vec1) > 0 and len(doc_vec2) > 0:\n",
        "    similarity = cosine_similarity([doc_vec1], [doc_vec2])[0][0]\n",
        "    if similarity > threshold:\n",
        "      return 1\n",
        "  \n",
        "  return 0\n",
        "\n",
        "# def predict_is_paraphrase_levenshtein(row, threshold):\n",
        "#   text1 = str(row[\"text\"])\n",
        "#   text2 = str(row[\"paraphrased_text\"])\n",
        "#   similarity = levenshtein(text1, text2)\n",
        "#   if similarity > threshold:\n",
        "#     return 1\n",
        "#   return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Q-qHk9rrA1"
      },
      "outputs": [],
      "source": [
        "model = models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1IzI0lSfraZ"
      },
      "outputs": [],
      "source": [
        "df = get_paraphrase_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzsepv4cqj-c"
      },
      "outputs": [],
      "source": [
        "dps_accuracy_scores = []\n",
        "dps_precision_scores = []\n",
        "dps_recall_scores = []\n",
        "dps_f1_scores = []\n",
        "\n",
        "for i in range(1, 10):\n",
        "  threshold = i / 10\n",
        "  df[\"dps_prediction_\" + str(threshold)] = df.apply(lambda x: predict_is_paraphrase_dps(x, threshold), axis = 1)\n",
        "  dps_accuracy_scores.append(accuracy_score(df[\"is_paraphrase\"], df[\"dps_prediction_\" + str(threshold)]))\n",
        "  dps_precision_scores.append(precision_score(df[\"is_paraphrase\"], df[\"dps_prediction_\" + str(threshold)]))\n",
        "  dps_recall_scores.append(recall_score(df[\"is_paraphrase\"], df[\"dps_prediction_\" + str(threshold)]))\n",
        "  dps_f1_scores.append(f1_score(df[\"is_paraphrase\"], df[\"dps_prediction_\" + str(threshold)]))\n",
        "  print(\"Threshold: \", str(threshold))\n",
        "  print(\"Accuracy Score: \". str(dps_accuracy_scores[-1]))\n",
        "  print(\"Precision Score: \". str(dps_precision_scores[-1]))\n",
        "  print(\"Recall Score: \". str(dps_recall_scores[-1]))\n",
        "  print(\"F1 Score: \". str(dps_f1_scores[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjLKWOMEPtrP"
      },
      "outputs": [],
      "source": [
        "# levenshtein_accuracy_scores = []\n",
        "# levenshtein_precision_scores = []\n",
        "# levenshtein_recall_scores = []\n",
        "# levenshtein_f1_scores = []\n",
        "\n",
        "# for i in range(1, 10):\n",
        "#   threshold = i / 10\n",
        "#   df[\"levenshtein_prediction_\" + str(threshold)] = df.apply(lambda x: predict_is_paraphrase_levenshtein(x, threshold), axis = 1)\n",
        "#   levenshtein_accuracy_scores.append(accuracy_score(df[\"is_paraphrase\"], df[\"levenshtein_prediction_\" + str(threshold)]))\n",
        "#   levenshtein_precision_scores.append(precision_score(df[\"is_paraphrase\"], df[\"levenshtein_prediction_\" + str(threshold)]))\n",
        "#   levenshtein_recall_scores.append(recall_score(df[\"is_paraphrase\"], df[\"levenshtein_prediction_\" + str(threshold)]))\n",
        "#   levenshtein_f1_scores.append(f1_score(df[\"is_paraphrase\"], df[\"levenshtein_prediction_\" + str(threshold)]))\n",
        "#   print(\"Threshold: \", str(threshold))\n",
        "#   print(\"Accuracy Score: \". str(levenshtein_accuracy_scores[-1]))\n",
        "#   print(\"Precision Score: \". str(levenshtein_precision_scores[-1]))\n",
        "#   print(\"Recall Score: \". str(levenshtein_recall_scores[-1]))\n",
        "#   print(\"F1 Score: \". str(levenshtein_f1_scores[-1]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc_YTVVhsVH2"
      },
      "outputs": [],
      "source": [
        "word2vec_accuracy_scores = []\n",
        "word2vec_precision_scores = []\n",
        "word2vec_recall_scores = []\n",
        "word2vec_f1_scores = []\n",
        "\n",
        "for i in range(1, 10):\n",
        "  threshold = i / 10\n",
        "  df[\"word2vec_prediction_\" + str(threshold)] = df.apply(lambda x: predict_is_paraphrase_word2vec(x, threshold), axis = 1)\n",
        "  word2vec_accuracy_scores.append(accuracy_score(df[\"is_paraphrase\"], df[\"word2vec_prediction_\" + str(threshold)]))\n",
        "  word2vec_precision_scores.append(precision_score(df[\"is_paraphrase\"], df[\"word2vec_prediction_\" + str(threshold)]))\n",
        "  word2vec_recall_scores.append(recall_score(df[\"is_paraphrase\"], df[\"word2vec_prediction_\" + str(threshold)]))\n",
        "  word2vec_f1_scores.append(f1_score(df[\"is_paraphrase\"], df[\"word2vec_prediction_\" + str(threshold)]))\n",
        "  print(\"Threshold: \", str(threshold))\n",
        "  print(\"Accuracy Score: \". str(word2vec_accuracy_scores[-1]))\n",
        "  print(\"Precision Score: \". str(word2vec_precision_scores[-1]))\n",
        "  print(\"Recall Score: \". str(word2vec_recall_scores[-1]))\n",
        "  print(\"F1 Score: \". str(word2vec_f1_scores[-1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LongAnswerScoringEvaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
